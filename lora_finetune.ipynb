{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89b89f64d8f8053d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# 单卡GPU 进行 ChatGLM3-6B模型 LORA 高效微调\n",
    "本 Cookbook 将带领开发者使用 `AdvertiseGen` 对 ChatGLM3-6B 数据集进行 lora微调，使其具备专业的广告生成能力。\n",
    "\n",
    "## 硬件需求\n",
    "显存：24GB\n",
    "显卡架构：安培架构（推荐）\n",
    "内存：16GB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bd9a514ed09ea6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 1. 准备数据集\n",
    "我们使用 AdvertiseGen 数据集来进行微调。从 [Google Drive](https://drive.google.com/file/d/13_vf0xRTQsyneRKdD1bZIr93vBGOczrk/view?usp=sharing) 或者 [Tsinghua Cloud](https://cloud.tsinghua.edu.cn/f/b3f119a008264b1cabd1/?dl=1) 下载处理好的 AdvertiseGen 数据集，将解压后的 AdvertiseGen 目录放到本目录的 `/data/` 下, 例如。\n",
    "> /media/zr/Data/Code/ChatGLM3/finetune_demo/data/AdvertiseGen\n",
    "\n",
    "接着，运行本代码来切割数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T05:02:34.749308Z",
     "start_time": "2024-01-18T05:02:25.564458Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Union\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _resolve_path(path: Union[str, Path]) -> Path:\n",
    "    return Path(path).expanduser().resolve()\n",
    "\n",
    "\n",
    "def _mkdir(dir_name: Union[str, Path]):\n",
    "    dir_name = _resolve_path(dir_name)\n",
    "    if not dir_name.is_dir():\n",
    "        dir_name.mkdir(parents=True, exist_ok=False)\n",
    "\n",
    "\n",
    "def convert_adgen(data_dir: Union[str, Path], save_dir: Union[str, Path]):\n",
    "    def _convert(in_file: Path, out_file: Path):\n",
    "        _mkdir(out_file.parent)\n",
    "        with open(in_file, encoding='utf-8') as fin:\n",
    "            with open(out_file, 'wt', encoding='utf-8') as fout:\n",
    "                for line in fin:\n",
    "                    dct = json.loads(line)\n",
    "                    sample = {'conversations': [{'role': 'user', 'content': dct['content']},\n",
    "                                                {'role': 'assistant', 'content': dct['summary']}]}\n",
    "                    fout.write(json.dumps(sample, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    data_dir = _resolve_path(data_dir)\n",
    "    save_dir = _resolve_path(save_dir)\n",
    "\n",
    "    train_file = data_dir / 'train.json'\n",
    "    if train_file.is_file():\n",
    "        out_file = save_dir / train_file.relative_to(data_dir)\n",
    "        _convert(train_file, out_file)\n",
    "\n",
    "    dev_file = data_dir / 'dev.json'\n",
    "    if dev_file.is_file():\n",
    "        out_file = save_dir / dev_file.relative_to(data_dir)\n",
    "        _convert(dev_file, out_file)\n",
    "\n",
    "\n",
    "convert_adgen('data/AdvertiseGen', 'data/AdvertiseGen_fix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b665ca13-4026-4fc9-b94b-6b5156bb7ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1b7a99923349056",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 2. 使用命令行开始微调,我们使用 lora 进行微调\n",
    "接着，我们仅需要将配置好的参数以命令行的形式传参给程序，就可以使用命令行进行高效微调，这里将 `/media/zr/Data/Code/ChatGLM3/venv/bin/python3` 换成你的 python3 的绝对路径以保证正常运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17c87410a24d844f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T06:44:56.043246Z",
     "start_time": "2024-01-18T05:05:28.425374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting eos_token is not supported, use the default one.\n",
      "Setting pad_token is not supported, use the default one.\n",
      "Setting unk_token is not supported, use the default one.\n",
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [00:02<00:00,  2.41it/s]\n",
      "trainable params: 1,949,696 || all params: 6,245,533,696 || trainable%: 0.031217444255383614\n",
      "--> Model\n",
      "\n",
      "--> model has 1.949696M params\n",
      "\n",
      "train_dataset: Dataset({\n",
      "    features: ['input_ids', 'labels'],\n",
      "    num_rows: 114599\n",
      "})\n",
      "Map (num_proc=4): 100%|████████████| 1070/1070 [00:00<00:00, 2128.81 examples/s]\n",
      "val_dataset: Dataset({\n",
      "    features: ['input_ids', 'output_ids'],\n",
      "    num_rows: 1070\n",
      "})\n",
      "test_dataset: Dataset({\n",
      "    features: ['input_ids', 'output_ids'],\n",
      "    num_rows: 1070\n",
      "})\n",
      "--> Sanity check\n",
      "           '[gMASK]': 64790 -> -100\n",
      "               'sop': 64792 -> -100\n",
      "          '<|user|>': 64795 -> -100\n",
      "                  '': 30910 -> -100\n",
      "                '\\n': 13 -> -100\n",
      "                  '': 30910 -> -100\n",
      "                '类型': 33467 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                 '裤': 56532 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                 '版': 55090 -> -100\n",
      "                 '型': 54888 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                '宽松': 40833 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                '风格': 32799 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                '性感': 40589 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                '图案': 37505 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                '线条': 37216 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                 '裤': 56532 -> -100\n",
      "                 '型': 54888 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                 '阔': 56529 -> -100\n",
      "                 '腿': 56158 -> -100\n",
      "                 '裤': 56532 -> -100\n",
      "     '<|assistant|>': 64796 -> -100\n",
      "                  '': 30910 -> 30910\n",
      "                '\\n': 13 -> 13\n",
      "                  '': 30910 -> 30910\n",
      "                '宽松': 40833 -> 40833\n",
      "                 '的': 54530 -> 54530\n",
      "                 '阔': 56529 -> 56529\n",
      "                 '腿': 56158 -> 56158\n",
      "                 '裤': 56532 -> 56532\n",
      "                 '这': 54551 -> 54551\n",
      "                '两年': 33808 -> 33808\n",
      "                '真的': 32041 -> 32041\n",
      "                 '吸': 55360 -> 55360\n",
      "                 '粉': 55486 -> 55486\n",
      "                '不少': 32138 -> 32138\n",
      "                 '，': 31123 -> 31123\n",
      "                '明星': 32943 -> 32943\n",
      "                '时尚': 33481 -> 33481\n",
      "                 '达': 54880 -> 54880\n",
      "                '人的': 31664 -> 31664\n",
      "                '心头': 46565 -> 46565\n",
      "                 '爱': 54799 -> 54799\n",
      "                 '。': 31155 -> 31155\n",
      "                '毕竟': 33051 -> 33051\n",
      "                 '好': 54591 -> 54591\n",
      "                 '穿': 55432 -> 55432\n",
      "                '时尚': 33481 -> 33481\n",
      "                 '，': 31123 -> 31123\n",
      "                 '谁': 55622 -> 55622\n",
      "                '都能': 32904 -> 32904\n",
      "                 '穿': 55432 -> 55432\n",
      "                 '出': 54557 -> 54557\n",
      "                 '腿': 56158 -> 56158\n",
      "                 '长': 54625 -> 54625\n",
      "                 '2': 30943 -> 30943\n",
      "                 '米': 55055 -> 55055\n",
      "               '的效果': 35590 -> 35590\n",
      "                '宽松': 40833 -> 40833\n",
      "                 '的': 54530 -> 54530\n",
      "                 '裤': 56532 -> 56532\n",
      "                 '腿': 56158 -> 56158\n",
      "                 '，': 31123 -> 31123\n",
      "               '当然是': 48466 -> 48466\n",
      "                 '遮': 57148 -> 57148\n",
      "                 '肉': 55343 -> 55343\n",
      "                 '小': 54603 -> 54603\n",
      "                '能手': 49355 -> 49355\n",
      "                 '啊': 55674 -> 55674\n",
      "                 '。': 31155 -> 31155\n",
      "                '上身': 51605 -> 51605\n",
      "                 '随': 55119 -> 55119\n",
      "                 '性': 54642 -> 54642\n",
      "                '自然': 31799 -> 31799\n",
      "                 '不': 54535 -> 54535\n",
      "                 '拘': 57036 -> 57036\n",
      "                 '束': 55625 -> 55625\n",
      "                 '，': 31123 -> 31123\n",
      "                '面料': 46839 -> 46839\n",
      "                 '亲': 55113 -> 55113\n",
      "                 '肤': 56089 -> 56089\n",
      "                '舒适': 33894 -> 33894\n",
      "                 '贴': 55778 -> 55778\n",
      "                '身体': 31902 -> 31902\n",
      "                 '验': 55017 -> 55017\n",
      "                 '感': 54706 -> 54706\n",
      "                 '棒': 56382 -> 56382\n",
      "                 '棒': 56382 -> 56382\n",
      "                 '哒': 59230 -> 59230\n",
      "                 '。': 31155 -> 31155\n",
      "                 '系': 54712 -> 54712\n",
      "                 '带': 54882 -> 54882\n",
      "                '部分': 31726 -> 31726\n",
      "                '增加': 31917 -> 31917\n",
      "                '设计': 31735 -> 31735\n",
      "                '看点': 45032 -> 45032\n",
      "                 '，': 31123 -> 31123\n",
      "                 '还': 54656 -> 54656\n",
      "                 '让': 54772 -> 54772\n",
      "                '单品': 46539 -> 46539\n",
      "               '的设计': 34481 -> 34481\n",
      "                 '感': 54706 -> 54706\n",
      "                '更强': 43084 -> 43084\n",
      "                 '。': 31155 -> 31155\n",
      "                '腿部': 46799 -> 46799\n",
      "                '线条': 37216 -> 37216\n",
      "                 '若': 55351 -> 55351\n",
      "                 '隐': 55733 -> 55733\n",
      "                 '若': 55351 -> 55351\n",
      "                 '现': 54600 -> 54600\n",
      "                 '的': 54530 -> 54530\n",
      "                 '，': 31123 -> 31123\n",
      "                '性感': 40589 -> 40589\n",
      "                 '撩': 58521 -> 58521\n",
      "                 '人': 54533 -> 54533\n",
      "                 '。': 31155 -> 31155\n",
      "                '颜色': 33692 -> 33692\n",
      "                 '敲': 57004 -> 57004\n",
      "                '温柔': 34678 -> 34678\n",
      "                 '的': 54530 -> 54530\n",
      "                 '，': 31123 -> 31123\n",
      "                 '与': 54619 -> 54619\n",
      "                '裤子': 44722 -> 44722\n",
      "                '本身': 32754 -> 32754\n",
      "                 '所': 54626 -> 54626\n",
      "                '呈现': 33169 -> 33169\n",
      "               '的风格': 48084 -> 48084\n",
      "                '有点': 33149 -> 33149\n",
      "                 '反': 54955 -> 54955\n",
      "                 '差': 55342 -> 55342\n",
      "                 '萌': 56842 -> 56842\n",
      "                 '。': 31155 -> 31155\n",
      "                  '': 2 -> 2\n",
      "/root/miniconda3/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "***** Running training *****\n",
      "  Num examples = 114,599\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3,000\n",
      "  Number of trainable parameters = 1,949,696\n",
      "{'loss': 4.2401, 'grad_norm': 5.52105712890625, 'learning_rate': 4.8333333333333334e-05, 'epoch': 0.0}\n",
      "{'loss': 3.7379, 'grad_norm': 6.617828369140625, 'learning_rate': 4.666666666666667e-05, 'epoch': 0.0}\n",
      "  7%|██▋                                     | 206/3000 [00:45<09:02,  5.15it/s]\n",
      " 16%|███████                                     | 8/50 [00:19<01:46,  2.53s/it]\u001b[A\n",
      " 18%|███████▉                                    | 9/50 [00:47<07:06, 10.41s/it]\u001b[A\n",
      " 20%|████████▌                                  | 10/50 [00:49<05:12,  7.81s/it]\u001b[A\n",
      " 22%|█████████▍                                 | 11/50 [00:52<04:07,  6.33s/it]\u001b[A\n",
      " 24%|██████████▎                                | 12/50 [00:55<03:22,  5.33s/it]\u001b[A\n",
      " 26%|███████████▏                               | 13/50 [00:58<02:47,  4.54s/it]\u001b[A\n",
      " 28%|████████████                               | 14/50 [01:00<02:25,  4.03s/it]\u001b[A\n",
      " 30%|████████████▉                              | 15/50 [01:04<02:19,  3.98s/it]\u001b[A\n",
      " 32%|█████████████▊                             | 16/50 [01:07<01:59,  3.52s/it]\u001b[A\n",
      " 34%|██████████████▌                            | 17/50 [01:10<01:58,  3.58s/it]\u001b[A\n",
      " 36%|███████████████▍                           | 18/50 [01:15<01:59,  3.75s/it]\u001b[A\n",
      " 38%|████████████████▎                          | 19/50 [01:17<01:41,  3.27s/it]\u001b[A\n",
      " 40%|█████████████████▏                         | 20/50 [01:20<01:34,  3.14s/it]\u001b[A\n",
      " 42%|██████████████████                         | 21/50 [01:24<01:37,  3.37s/it]\u001b[A\n",
      " 44%|██████████████████▉                        | 22/50 [01:29<01:49,  3.92s/it]\u001b[A\n",
      " 46%|███████████████████▊                       | 23/50 [01:32<01:36,  3.59s/it]\u001b[A\n",
      " 48%|████████████████████▋                      | 24/50 [01:35<01:32,  3.56s/it]\u001b[A\n",
      " 50%|█████████████████████▌                     | 25/50 [01:38<01:25,  3.41s/it]\u001b[A\n",
      " 52%|██████████████████████▎                    | 26/50 [01:42<01:22,  3.45s/it]\u001b[A\n",
      " 54%|███████████████████████▏                   | 27/50 [01:46<01:23,  3.64s/it]\u001b[A\n",
      " 56%|████████████████████████                   | 28/50 [01:48<01:13,  3.34s/it]\u001b[A\n",
      " 58%|████████████████████████▉                  | 29/50 [01:52<01:11,  3.39s/it]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 30/50 [01:56<01:12,  3.63s/it]\u001b[A\n",
      " 62%|██████████████████████████▋                | 31/50 [01:59<01:05,  3.46s/it]\u001b[A\n",
      " 64%|███████████████████████████▌               | 32/50 [02:02<01:01,  3.41s/it]\u001b[A\n",
      " 66%|████████████████████████████▍              | 33/50 [02:06<01:00,  3.55s/it]\u001b[A\n",
      " 68%|█████████████████████████████▏             | 34/50 [02:09<00:51,  3.23s/it]\u001b[A\n",
      " 70%|██████████████████████████████             | 35/50 [02:12<00:47,  3.15s/it]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 36/50 [02:16<00:47,  3.38s/it]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 37/50 [02:18<00:39,  3.00s/it]\u001b[A\n",
      " 76%|████████████████████████████████▋          | 38/50 [02:21<00:38,  3.17s/it]\u001b[A\n",
      " 78%|█████████████████████████████████▌         | 39/50 [02:24<00:33,  3.04s/it]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 40/50 [02:27<00:29,  2.90s/it]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 41/50 [02:30<00:26,  2.97s/it]\u001b[A\n",
      " 84%|████████████████████████████████████       | 42/50 [02:33<00:24,  3.04s/it]\u001b[A\n",
      " 86%|████████████████████████████████████▉      | 43/50 [02:37<00:22,  3.28s/it]\u001b[A\n",
      " 88%|█████████████████████████████████████▊     | 44/50 [02:39<00:18,  3.09s/it]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 45/50 [02:42<00:15,  3.05s/it]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 46/50 [02:45<00:11,  2.82s/it]\u001b[A\n",
      " 94%|████████████████████████████████████████▍  | 47/50 [02:47<00:08,  2.71s/it]\u001b[A\n",
      " 96%|█████████████████████████████████████████▎ | 48/50 [02:51<00:05,  2.97s/it]\u001b[A\n",
      " 98%|██████████████████████████████████████████▏| 49/50 [02:53<00:02,  2.60s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████| 50/50 [02:55<00:00,  2.71s/it]\u001b[ABuilding prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.674 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "                                                                                \n",
      "\u001b[A{'eval_rouge-1': 30.133364000000007, 'eval_rouge-2': 6.265516000000002, 'eval_rouge-l': 23.928564, 'eval_bleu-4': 0.03184509862892148, 'eval_runtime': 181.0382, 'eval_samples_per_second': 0.276, 'eval_steps_per_second': 0.276, 'epoch': 0.0}\n",
      " 17%|██████▋                                 | 500/3000 [04:50<09:16,  4.49it/s]\n",
      "100%|███████████████████████████████████████████| 50/50 [02:56<00:00,  2.71s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-500\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/a5ba5501eb873d40d48bd0983bd2a8dd006bb838/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.39.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./output/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-500/special_tokens_map.json\n",
      "{'loss': 3.5118, 'grad_norm': 7.150425434112549, 'learning_rate': 4e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4729, 'grad_norm': 12.604666709899902, 'learning_rate': 3.8333333333333334e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4205, 'grad_norm': 9.1024751663208, 'learning_rate': 3.6666666666666666e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4703, 'grad_norm': 7.691667556762695, 'learning_rate': 3.5e-05, 'epoch': 0.01}\n",
      "{'loss': 3.3383, 'grad_norm': 10.147483825683594, 'learning_rate': 3.3333333333333335e-05, 'epoch': 0.01}\n",
      " 33%|█████████████                          | 1000/3000 [06:47<07:10,  4.64it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 1\n",
      "\n",
      "  0%|                                                    | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|█▊                                          | 2/50 [00:03<01:20,  1.67s/it]\u001b[A\n",
      "  6%|██▋                                         | 3/50 [00:06<01:42,  2.18s/it]\u001b[A\n",
      "  8%|███▌                                        | 4/50 [00:34<09:04, 11.83s/it]\u001b[A\n",
      " 10%|████▍                                       | 5/50 [00:37<06:41,  8.92s/it]\u001b[A\n",
      " 12%|█████▎                                      | 6/50 [00:40<05:03,  6.91s/it]\u001b[A\n",
      " 14%|██████▏                                     | 7/50 [00:44<04:16,  5.96s/it]\u001b[A\n",
      " 16%|███████                                     | 8/50 [00:46<03:18,  4.74s/it]\u001b[A\n",
      " 18%|███████▉                                    | 9/50 [00:49<02:52,  4.21s/it]\u001b[A\n",
      " 20%|████████▌                                  | 10/50 [00:52<02:30,  3.75s/it]\u001b[A\n",
      " 22%|█████████▍                                 | 11/50 [00:55<02:19,  3.56s/it]\u001b[A\n",
      " 24%|██████████▎                                | 12/50 [00:59<02:17,  3.62s/it]\u001b[A\n",
      " 26%|███████████▏                               | 13/50 [01:02<02:13,  3.60s/it]\u001b[A\n",
      " 28%|████████████                               | 14/50 [01:05<02:00,  3.36s/it]\u001b[A\n",
      " 30%|████████████▉                              | 15/50 [01:09<01:59,  3.41s/it]\u001b[A\n",
      " 32%|█████████████▊                             | 16/50 [01:12<01:52,  3.31s/it]\u001b[A\n",
      " 34%|██████████████▌                            | 17/50 [01:15<01:45,  3.19s/it]\u001b[A\n",
      " 36%|███████████████▍                           | 18/50 [01:19<01:49,  3.41s/it]\u001b[A\n",
      " 38%|████████████████▎                          | 19/50 [01:22<01:48,  3.49s/it]\u001b[A\n",
      " 40%|█████████████████▏                         | 20/50 [01:25<01:35,  3.18s/it]\u001b[A\n",
      " 42%|██████████████████                         | 21/50 [01:28<01:33,  3.22s/it]\u001b[A\n",
      " 44%|██████████████████▉                        | 22/50 [01:32<01:33,  3.34s/it]\u001b[A\n",
      " 46%|███████████████████▊                       | 23/50 [01:35<01:29,  3.33s/it]\u001b[A\n",
      " 48%|████████████████████▋                      | 24/50 [02:03<04:39, 10.75s/it]\u001b[A\n",
      " 50%|█████████████████████▌                     | 25/50 [02:07<03:37,  8.69s/it]\u001b[A\n",
      " 52%|██████████████████████▎                    | 26/50 [02:10<02:48,  7.00s/it]\u001b[A\n",
      " 54%|███████████████████████▏                   | 27/50 [02:15<02:28,  6.48s/it]\u001b[A\n",
      " 56%|████████████████████████                   | 28/50 [02:18<02:01,  5.51s/it]\u001b[A\n",
      " 58%|████████████████████████▉                  | 29/50 [02:22<01:45,  5.03s/it]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 30/50 [02:26<01:30,  4.51s/it]\u001b[A\n",
      " 62%|██████████████████████████▋                | 31/50 [02:30<01:24,  4.42s/it]\u001b[A\n",
      " 64%|███████████████████████████▌               | 32/50 [02:33<01:12,  4.04s/it]\u001b[A\n",
      " 66%|████████████████████████████▍              | 33/50 [02:36<01:02,  3.68s/it]\u001b[A\n",
      " 68%|█████████████████████████████▏             | 34/50 [02:40<00:58,  3.67s/it]\u001b[A\n",
      " 70%|██████████████████████████████             | 35/50 [02:43<00:56,  3.74s/it]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 36/50 [02:47<00:52,  3.76s/it]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 37/50 [02:50<00:45,  3.49s/it]\u001b[A\n",
      " 76%|████████████████████████████████▋          | 38/50 [02:54<00:44,  3.69s/it]\u001b[A\n",
      " 78%|█████████████████████████████████▌         | 39/50 [02:57<00:37,  3.44s/it]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 40/50 [03:01<00:34,  3.49s/it]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 41/50 [03:03<00:29,  3.25s/it]\u001b[A\n",
      " 84%|████████████████████████████████████       | 42/50 [03:07<00:26,  3.30s/it]\u001b[A\n",
      " 86%|████████████████████████████████████▉      | 43/50 [03:10<00:22,  3.19s/it]\u001b[A\n",
      " 88%|█████████████████████████████████████▊     | 44/50 [03:13<00:18,  3.09s/it]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 45/50 [03:16<00:16,  3.20s/it]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 46/50 [03:20<00:13,  3.30s/it]\u001b[A\n",
      " 94%|████████████████████████████████████████▍  | 47/50 [03:22<00:09,  3.14s/it]\u001b[A\n",
      " 96%|█████████████████████████████████████████▎ | 48/50 [03:26<00:06,  3.34s/it]\u001b[A\n",
      " 98%|██████████████████████████████████████████▏| 49/50 [03:29<00:03,  3.17s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 29.645802, 'eval_rouge-2': 6.232340000000001, 'eval_rouge-l': 23.782630000000005, 'eval_bleu-4': 0.030997422363357865, 'eval_runtime': 216.7676, 'eval_samples_per_second': 0.231, 'eval_steps_per_second': 0.231, 'epoch': 0.01}\n",
      " 33%|█████████████                          | 1000/3000 [10:23<07:10,  4.64it/s]\n",
      "100%|███████████████████████████████████████████| 50/50 [03:33<00:00,  3.28s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-1000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/a5ba5501eb873d40d48bd0983bd2a8dd006bb838/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.39.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./output/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-1000/special_tokens_map.json\n",
      "{'loss': 3.4664, 'grad_norm': 11.120231628417969, 'learning_rate': 3.1666666666666666e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4181, 'grad_norm': 9.833677291870117, 'learning_rate': 3e-05, 'epoch': 0.01}\n",
      "{'loss': 3.3845, 'grad_norm': 12.81195068359375, 'learning_rate': 2.8333333333333335e-05, 'epoch': 0.01}\n",
      "{'loss': 3.3228, 'grad_norm': 10.372461318969727, 'learning_rate': 2.6666666666666667e-05, 'epoch': 0.01}\n",
      "{'loss': 3.3425, 'grad_norm': 12.01992130279541, 'learning_rate': 2.5e-05, 'epoch': 0.01}\n",
      " 50%|███████████████████▌                   | 1500/3000 [12:19<05:11,  4.82it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 1\n",
      "\n",
      "  0%|                                                    | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|█▊                                          | 2/50 [00:03<01:18,  1.64s/it]\u001b[A\n",
      "  6%|██▋                                         | 3/50 [00:06<01:41,  2.16s/it]\u001b[A\n",
      "  8%|███▌                                        | 4/50 [00:34<09:02, 11.79s/it]\u001b[A\n",
      " 10%|████▍                                       | 5/50 [00:37<06:46,  9.02s/it]\u001b[A\n",
      " 12%|█████▎                                      | 6/50 [00:41<05:13,  7.12s/it]\u001b[A\n",
      " 14%|██████▏                                     | 7/50 [01:09<09:56, 13.86s/it]\u001b[A\n",
      " 16%|███████                                     | 8/50 [01:12<07:18, 10.44s/it]\u001b[A\n",
      " 18%|███████▉                                    | 9/50 [01:16<05:43,  8.38s/it]\u001b[A\n",
      " 20%|████████▌                                  | 10/50 [01:18<04:24,  6.61s/it]\u001b[A\n",
      " 22%|█████████▍                                 | 11/50 [01:21<03:36,  5.56s/it]\u001b[A\n",
      " 24%|██████████▎                                | 12/50 [01:24<02:56,  4.65s/it]\u001b[A\n",
      " 26%|███████████▏                               | 13/50 [01:27<02:29,  4.05s/it]\u001b[A\n",
      " 28%|████████████                               | 14/50 [01:29<02:09,  3.60s/it]\u001b[A\n",
      " 30%|████████████▉                              | 15/50 [01:32<01:58,  3.39s/it]\u001b[A\n",
      " 32%|█████████████▊                             | 16/50 [01:36<01:59,  3.53s/it]\u001b[A\n",
      " 34%|██████████████▌                            | 17/50 [01:40<01:58,  3.60s/it]\u001b[A\n",
      " 36%|███████████████▍                           | 18/50 [01:43<01:54,  3.58s/it]\u001b[A\n",
      " 38%|████████████████▎                          | 19/50 [01:46<01:45,  3.42s/it]\u001b[A\n",
      " 40%|█████████████████▏                         | 20/50 [01:49<01:36,  3.23s/it]\u001b[A\n",
      " 42%|██████████████████                         | 21/50 [01:53<01:39,  3.43s/it]\u001b[A\n",
      " 44%|██████████████████▉                        | 22/50 [01:57<01:37,  3.47s/it]\u001b[A\n",
      " 46%|███████████████████▊                       | 23/50 [02:00<01:32,  3.42s/it]\u001b[A\n",
      " 48%|████████████████████▋                      | 24/50 [02:03<01:28,  3.41s/it]\u001b[A\n",
      " 50%|█████████████████████▌                     | 25/50 [02:07<01:29,  3.59s/it]\u001b[A\n",
      " 52%|██████████████████████▎                    | 26/50 [02:10<01:19,  3.32s/it]\u001b[A\n",
      " 54%|███████████████████████▏                   | 27/50 [02:14<01:23,  3.64s/it]\u001b[A\n",
      " 56%|████████████████████████                   | 28/50 [02:17<01:12,  3.28s/it]\u001b[A\n",
      " 58%|████████████████████████▉                  | 29/50 [02:21<01:16,  3.67s/it]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 30/50 [02:24<01:09,  3.48s/it]\u001b[A\n",
      " 62%|██████████████████████████▋                | 31/50 [02:29<01:11,  3.76s/it]\u001b[A\n",
      " 64%|███████████████████████████▌               | 32/50 [02:32<01:04,  3.61s/it]\u001b[A\n",
      " 66%|████████████████████████████▍              | 33/50 [02:35<00:59,  3.51s/it]\u001b[A\n",
      " 68%|█████████████████████████████▏             | 34/50 [02:38<00:54,  3.39s/it]\u001b[A\n",
      " 70%|██████████████████████████████             | 35/50 [02:42<00:53,  3.59s/it]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 36/50 [02:46<00:49,  3.54s/it]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 37/50 [02:49<00:43,  3.33s/it]\u001b[A\n",
      " 76%|████████████████████████████████▋          | 38/50 [02:51<00:36,  3.02s/it]\u001b[A\n",
      " 78%|█████████████████████████████████▌         | 39/50 [02:53<00:31,  2.83s/it]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 40/50 [02:57<00:30,  3.10s/it]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 41/50 [03:00<00:28,  3.14s/it]\u001b[A\n",
      " 84%|████████████████████████████████████       | 42/50 [03:04<00:25,  3.17s/it]\u001b[A\n",
      " 86%|████████████████████████████████████▉      | 43/50 [03:07<00:22,  3.21s/it]\u001b[A\n",
      " 88%|█████████████████████████████████████▊     | 44/50 [03:10<00:19,  3.30s/it]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 45/50 [03:13<00:15,  3.09s/it]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 46/50 [03:18<00:14,  3.51s/it]\u001b[A\n",
      " 94%|████████████████████████████████████████▍  | 47/50 [03:20<00:09,  3.21s/it]\u001b[A\n",
      " 96%|█████████████████████████████████████████▎ | 48/50 [03:24<00:06,  3.32s/it]\u001b[A\n",
      " 98%|██████████████████████████████████████████▏| 49/50 [03:29<00:03,  3.86s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 30.382057999999997, 'eval_rouge-2': 6.268, 'eval_rouge-l': 23.763423999999997, 'eval_bleu-4': 0.032246008342830555, 'eval_runtime': 217.4323, 'eval_samples_per_second': 0.23, 'eval_steps_per_second': 0.23, 'epoch': 0.01}\n",
      " 50%|███████████████████▌                   | 1500/3000 [15:56<05:11,  4.82it/s]\n",
      "100%|███████████████████████████████████████████| 50/50 [03:33<00:00,  3.92s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-1500\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/a5ba5501eb873d40d48bd0983bd2a8dd006bb838/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.39.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./output/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-1500/special_tokens_map.json\n",
      "{'loss': 3.3906, 'grad_norm': 9.021210670471191, 'learning_rate': 2.3333333333333336e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4568, 'grad_norm': 11.1941556930542, 'learning_rate': 2.1666666666666667e-05, 'epoch': 0.01}\n",
      "{'loss': 3.3347, 'grad_norm': 10.239771842956543, 'learning_rate': 2e-05, 'epoch': 0.02}\n",
      "{'loss': 3.3106, 'grad_norm': 8.8855562210083, 'learning_rate': 1.8333333333333333e-05, 'epoch': 0.02}\n",
      "{'loss': 3.3588, 'grad_norm': 10.293018341064453, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.02}\n",
      " 67%|██████████████████████████             | 2000/3000 [17:52<04:17,  3.88it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 1\n",
      "\n",
      "  0%|                                                    | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|█▊                                          | 2/50 [00:02<00:57,  1.20s/it]\u001b[A\n",
      "  6%|██▋                                         | 3/50 [00:05<01:25,  1.82s/it]\u001b[A\n",
      "  8%|███▌                                        | 4/50 [00:33<08:53, 11.59s/it]\u001b[A\n",
      " 10%|████▍                                       | 5/50 [00:35<06:25,  8.57s/it]\u001b[A\n",
      " 12%|█████▎                                      | 6/50 [00:40<05:14,  7.14s/it]\u001b[A\n",
      " 14%|██████▏                                     | 7/50 [00:42<04:04,  5.68s/it]\u001b[A\n",
      " 16%|███████                                     | 8/50 [00:45<03:18,  4.72s/it]\u001b[A\n",
      " 18%|███████▉                                    | 9/50 [00:48<02:46,  4.06s/it]\u001b[A\n",
      " 20%|████████▌                                  | 10/50 [00:50<02:23,  3.60s/it]\u001b[A\n",
      " 22%|█████████▍                                 | 11/50 [00:55<02:31,  3.87s/it]\u001b[A\n",
      " 24%|██████████▎                                | 12/50 [00:57<02:12,  3.48s/it]\u001b[A\n",
      " 26%|███████████▏                               | 13/50 [01:00<02:00,  3.27s/it]\u001b[A\n",
      " 28%|████████████                               | 14/50 [01:03<01:53,  3.15s/it]\u001b[A\n",
      " 30%|████████████▉                              | 15/50 [01:07<02:02,  3.51s/it]\u001b[A\n",
      " 32%|█████████████▊                             | 16/50 [01:10<01:55,  3.40s/it]\u001b[A\n",
      " 34%|██████████████▌                            | 17/50 [01:13<01:46,  3.23s/it]\u001b[A\n",
      " 36%|███████████████▍                           | 18/50 [01:17<01:49,  3.41s/it]\u001b[A\n",
      " 38%|████████████████▎                          | 19/50 [01:20<01:45,  3.41s/it]\u001b[A\n",
      " 40%|█████████████████▏                         | 20/50 [01:23<01:39,  3.30s/it]\u001b[A\n",
      " 42%|██████████████████                         | 21/50 [01:28<01:45,  3.62s/it]\u001b[A\n",
      " 44%|██████████████████▉                        | 22/50 [01:32<01:48,  3.87s/it]\u001b[A\n",
      " 46%|███████████████████▊                       | 23/50 [01:35<01:37,  3.62s/it]\u001b[A\n",
      " 48%|████████████████████▋                      | 24/50 [02:03<04:45, 10.96s/it]\u001b[A\n",
      " 50%|█████████████████████▌                     | 25/50 [02:06<03:34,  8.58s/it]\u001b[A\n",
      " 52%|██████████████████████▎                    | 26/50 [02:09<02:41,  6.75s/it]\u001b[A\n",
      " 54%|███████████████████████▏                   | 27/50 [02:14<02:21,  6.13s/it]\u001b[A\n",
      " 56%|████████████████████████                   | 28/50 [02:15<01:46,  4.85s/it]\u001b[A\n",
      " 58%|████████████████████████▉                  | 29/50 [02:20<01:40,  4.78s/it]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 30/50 [02:48<03:56, 11.81s/it]\u001b[A\n",
      " 62%|██████████████████████████▋                | 31/50 [02:52<02:56,  9.29s/it]\u001b[A\n",
      " 64%|███████████████████████████▌               | 32/50 [02:55<02:16,  7.56s/it]\u001b[A\n",
      " 66%|████████████████████████████▍              | 33/50 [02:58<01:41,  6.00s/it]\u001b[A\n",
      " 68%|█████████████████████████████▏             | 34/50 [03:02<01:30,  5.66s/it]\u001b[A\n",
      " 70%|██████████████████████████████             | 35/50 [03:06<01:16,  5.11s/it]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 36/50 [03:09<01:03,  4.51s/it]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 37/50 [03:11<00:49,  3.78s/it]\u001b[A\n",
      " 76%|████████████████████████████████▋          | 38/50 [03:15<00:44,  3.74s/it]\u001b[A\n",
      " 78%|█████████████████████████████████▌         | 39/50 [03:18<00:37,  3.44s/it]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 40/50 [03:21<00:32,  3.22s/it]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 41/50 [03:25<00:31,  3.45s/it]\u001b[A\n",
      " 84%|████████████████████████████████████       | 42/50 [03:27<00:25,  3.22s/it]\u001b[A\n",
      " 86%|████████████████████████████████████▉      | 43/50 [03:30<00:21,  3.13s/it]\u001b[A\n",
      " 88%|█████████████████████████████████████▊     | 44/50 [03:34<00:19,  3.20s/it]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 45/50 [03:36<00:14,  2.92s/it]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 46/50 [03:38<00:11,  2.81s/it]\u001b[A\n",
      " 94%|████████████████████████████████████████▍  | 47/50 [03:41<00:07,  2.64s/it]\u001b[A\n",
      " 96%|█████████████████████████████████████████▎ | 48/50 [03:43<00:04,  2.46s/it]\u001b[A\n",
      " 98%|██████████████████████████████████████████▏| 49/50 [03:46<00:02,  2.67s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 30.960652, 'eval_rouge-2': 6.8447059999999995, 'eval_rouge-l': 23.805955999999995, 'eval_bleu-4': 0.030315405920553897, 'eval_runtime': 232.8446, 'eval_samples_per_second': 0.215, 'eval_steps_per_second': 0.215, 'epoch': 0.02}\n",
      " 67%|██████████████████████████             | 2000/3000 [21:45<04:17,  3.88it/s]\n",
      "100%|███████████████████████████████████████████| 50/50 [03:49<00:00,  2.85s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-2000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/a5ba5501eb873d40d48bd0983bd2a8dd006bb838/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.39.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./output/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-2000/special_tokens_map.json\n",
      "{'loss': 3.3474, 'grad_norm': 13.667275428771973, 'learning_rate': 1.5e-05, 'epoch': 0.02}\n",
      "{'loss': 3.3605, 'grad_norm': 10.303666114807129, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4016, 'grad_norm': 11.07616901397705, 'learning_rate': 1.1666666666666668e-05, 'epoch': 0.02}\n",
      "{'loss': 3.3164, 'grad_norm': 11.872063636779785, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 3.3063, 'grad_norm': 12.963152885437012, 'learning_rate': 8.333333333333334e-06, 'epoch': 0.02}\n",
      " 83%|████████████████████████████████▌      | 2500/3000 [23:42<01:37,  5.12it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 1\n",
      "\n",
      "  0%|                                                    | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|█▊                                          | 2/50 [00:02<01:09,  1.45s/it]\u001b[A\n",
      "  6%|██▋                                         | 3/50 [00:06<01:45,  2.25s/it]\u001b[A\n",
      "  8%|███▌                                        | 4/50 [00:34<09:05, 11.87s/it]\u001b[A\n",
      " 10%|████▍                                       | 5/50 [00:37<06:31,  8.69s/it]\u001b[A\n",
      " 12%|█████▎                                      | 6/50 [00:40<05:05,  6.93s/it]\u001b[A\n",
      " 14%|██████▏                                     | 7/50 [00:43<04:02,  5.64s/it]\u001b[A\n",
      " 16%|███████                                     | 8/50 [00:45<03:12,  4.57s/it]\u001b[A\n",
      " 18%|███████▉                                    | 9/50 [00:48<02:44,  4.01s/it]\u001b[A\n",
      " 20%|████████▌                                  | 10/50 [00:51<02:26,  3.66s/it]\u001b[A\n",
      " 22%|█████████▍                                 | 11/50 [00:54<02:17,  3.52s/it]\u001b[A\n",
      " 24%|██████████▎                                | 12/50 [01:22<06:56, 10.97s/it]\u001b[A\n",
      " 26%|███████████▏                               | 13/50 [01:25<05:12,  8.44s/it]\u001b[A\n",
      " 28%|████████████                               | 14/50 [01:27<04:03,  6.76s/it]\u001b[A\n",
      " 30%|████████████▉                              | 15/50 [01:32<03:33,  6.09s/it]\u001b[A\n",
      " 32%|█████████████▊                             | 16/50 [01:35<02:56,  5.18s/it]\u001b[A\n",
      " 34%|██████████████▌                            | 17/50 [01:38<02:32,  4.63s/it]\u001b[A\n",
      " 36%|███████████████▍                           | 18/50 [01:43<02:25,  4.54s/it]\u001b[A\n",
      " 38%|████████████████▎                          | 19/50 [01:45<02:01,  3.91s/it]\u001b[A\n",
      " 40%|█████████████████▏                         | 20/50 [01:48<01:48,  3.62s/it]\u001b[A\n",
      " 42%|██████████████████                         | 21/50 [01:52<01:46,  3.68s/it]\u001b[A\n",
      " 44%|██████████████████▉                        | 22/50 [01:55<01:37,  3.50s/it]\u001b[A\n",
      " 46%|███████████████████▊                       | 23/50 [01:59<01:35,  3.55s/it]\u001b[A\n",
      " 48%|████████████████████▋                      | 24/50 [02:02<01:29,  3.44s/it]\u001b[A\n",
      " 50%|█████████████████████▌                     | 25/50 [02:05<01:22,  3.28s/it]\u001b[A\n",
      " 52%|██████████████████████▎                    | 26/50 [02:08<01:16,  3.18s/it]\u001b[A\n",
      " 54%|███████████████████████▏                   | 27/50 [02:14<01:37,  4.22s/it]\u001b[A\n",
      " 56%|████████████████████████                   | 28/50 [02:16<01:18,  3.56s/it]\u001b[A\n",
      " 58%|████████████████████████▉                  | 29/50 [02:20<01:13,  3.48s/it]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 30/50 [02:22<01:04,  3.22s/it]\u001b[A\n",
      " 62%|██████████████████████████▋                | 31/50 [02:26<01:03,  3.32s/it]\u001b[A\n",
      " 64%|███████████████████████████▌               | 32/50 [02:29<00:58,  3.25s/it]\u001b[A\n",
      " 66%|████████████████████████████▍              | 33/50 [02:31<00:50,  2.95s/it]\u001b[A\n",
      " 68%|█████████████████████████████▏             | 34/50 [02:35<00:50,  3.15s/it]\u001b[A\n",
      " 70%|██████████████████████████████             | 35/50 [02:39<00:52,  3.51s/it]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 36/50 [02:43<00:49,  3.50s/it]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 37/50 [02:46<00:43,  3.38s/it]\u001b[A\n",
      " 76%|████████████████████████████████▋          | 38/50 [02:49<00:39,  3.28s/it]\u001b[A\n",
      " 78%|█████████████████████████████████▌         | 39/50 [02:51<00:33,  3.07s/it]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 40/50 [02:55<00:31,  3.17s/it]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 41/50 [02:58<00:28,  3.12s/it]\u001b[A\n",
      " 84%|████████████████████████████████████       | 42/50 [03:00<00:22,  2.85s/it]\u001b[A\n",
      " 86%|████████████████████████████████████▉      | 43/50 [03:03<00:20,  2.96s/it]\u001b[A\n",
      " 88%|█████████████████████████████████████▊     | 44/50 [03:06<00:17,  2.89s/it]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 45/50 [03:09<00:14,  2.90s/it]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 46/50 [03:11<00:10,  2.62s/it]\u001b[A\n",
      " 94%|████████████████████████████████████████▍  | 47/50 [03:13<00:07,  2.41s/it]\u001b[A\n",
      " 96%|█████████████████████████████████████████▎ | 48/50 [03:15<00:04,  2.46s/it]\u001b[A\n",
      " 98%|██████████████████████████████████████████▏| 49/50 [03:17<00:02,  2.37s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 31.006278000000002, 'eval_rouge-2': 6.848310000000001, 'eval_rouge-l': 23.571872, 'eval_bleu-4': 0.031574384491963176, 'eval_runtime': 206.7113, 'eval_samples_per_second': 0.242, 'eval_steps_per_second': 0.242, 'epoch': 0.02}\n",
      " 83%|████████████████████████████████▌      | 2500/3000 [27:09<01:37,  5.12it/s]\n",
      "100%|███████████████████████████████████████████| 50/50 [03:23<00:00,  3.19s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-2500\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/a5ba5501eb873d40d48bd0983bd2a8dd006bb838/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.39.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./output/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-2500/special_tokens_map.json\n",
      "{'loss': 3.3731, 'grad_norm': 11.843358039855957, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.02}\n",
      "{'loss': 3.3622, 'grad_norm': 9.48766040802002, 'learning_rate': 5e-06, 'epoch': 0.02}\n",
      "{'loss': 3.2287, 'grad_norm': 11.808682441711426, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.02}\n",
      "{'loss': 3.3249, 'grad_norm': 12.113097190856934, 'learning_rate': 1.6666666666666667e-06, 'epoch': 0.03}\n",
      "{'loss': 3.3056, 'grad_norm': 10.852023124694824, 'learning_rate': 0.0, 'epoch': 0.03}\n",
      "100%|███████████████████████████████████████| 3000/3000 [29:05<00:00,  4.91it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 1\n",
      "\n",
      "  0%|                                                    | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|█▊                                          | 2/50 [00:03<01:12,  1.50s/it]\u001b[A\n",
      "  6%|██▋                                         | 3/50 [00:05<01:34,  2.02s/it]\u001b[A\n",
      "  8%|███▌                                        | 4/50 [00:08<01:44,  2.28s/it]\u001b[A\n",
      " 10%|████▍                                       | 5/50 [00:11<01:54,  2.55s/it]\u001b[A\n",
      " 12%|█████▎                                      | 6/50 [00:15<02:06,  2.89s/it]\u001b[A\n",
      " 14%|██████▏                                     | 7/50 [00:43<07:52, 11.00s/it]\u001b[A\n",
      " 16%|███████                                     | 8/50 [00:45<05:47,  8.27s/it]\u001b[A\n",
      " 18%|███████▉                                    | 9/50 [00:48<04:27,  6.51s/it]\u001b[A\n",
      " 20%|████████▌                                  | 10/50 [00:51<03:37,  5.43s/it]\u001b[A\n",
      " 22%|█████████▍                                 | 11/50 [00:54<03:09,  4.85s/it]\u001b[A\n",
      " 24%|██████████▎                                | 12/50 [00:57<02:43,  4.30s/it]\u001b[A\n",
      " 26%|███████████▏                               | 13/50 [01:00<02:24,  3.91s/it]\u001b[A\n",
      " 28%|████████████                               | 14/50 [01:03<02:12,  3.68s/it]\u001b[A\n",
      " 30%|████████████▉                              | 15/50 [01:09<02:24,  4.13s/it]\u001b[A\n",
      " 32%|█████████████▊                             | 16/50 [01:11<02:05,  3.68s/it]\u001b[A\n",
      " 34%|██████████████▌                            | 17/50 [01:14<01:53,  3.43s/it]\u001b[A\n",
      " 36%|███████████████▍                           | 18/50 [01:19<02:04,  3.88s/it]\u001b[A\n",
      " 38%|████████████████▎                          | 19/50 [01:21<01:46,  3.42s/it]\u001b[A\n",
      " 40%|█████████████████▏                         | 20/50 [01:24<01:36,  3.23s/it]\u001b[A\n",
      " 42%|██████████████████                         | 21/50 [01:52<05:10, 10.71s/it]\u001b[A\n",
      " 44%|██████████████████▉                        | 22/50 [01:57<04:10,  8.95s/it]\u001b[A\n",
      " 46%|███████████████████▊                       | 23/50 [02:00<03:10,  7.06s/it]\u001b[A\n",
      " 48%|████████████████████▋                      | 24/50 [02:03<02:35,  5.98s/it]\u001b[A\n",
      " 50%|█████████████████████▌                     | 25/50 [02:05<02:01,  4.86s/it]\u001b[A\n",
      " 52%|██████████████████████▎                    | 26/50 [02:08<01:43,  4.29s/it]\u001b[A\n",
      " 54%|███████████████████████▏                   | 27/50 [02:13<01:38,  4.30s/it]\u001b[A\n",
      " 56%|████████████████████████                   | 28/50 [02:16<01:27,  3.97s/it]\u001b[A\n",
      " 58%|████████████████████████▉                  | 29/50 [02:19<01:18,  3.72s/it]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 30/50 [02:23<01:13,  3.69s/it]\u001b[A\n",
      " 62%|██████████████████████████▋                | 31/50 [02:26<01:06,  3.52s/it]\u001b[A\n",
      " 64%|███████████████████████████▌               | 32/50 [02:29<01:01,  3.41s/it]\u001b[A\n",
      " 66%|████████████████████████████▍              | 33/50 [02:32<00:53,  3.16s/it]\u001b[A\n",
      " 68%|█████████████████████████████▏             | 34/50 [02:35<00:51,  3.21s/it]\u001b[A\n",
      " 70%|██████████████████████████████             | 35/50 [02:38<00:49,  3.31s/it]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 36/50 [02:42<00:47,  3.38s/it]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 37/50 [02:44<00:40,  3.10s/it]\u001b[A\n",
      " 76%|████████████████████████████████▋          | 38/50 [02:47<00:34,  2.90s/it]\u001b[A\n",
      " 78%|█████████████████████████████████▌         | 39/50 [02:49<00:30,  2.76s/it]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 40/50 [02:53<00:29,  2.98s/it]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 41/50 [02:56<00:26,  3.00s/it]\u001b[A\n",
      " 84%|████████████████████████████████████       | 42/50 [02:58<00:22,  2.86s/it]\u001b[A\n",
      " 86%|████████████████████████████████████▉      | 43/50 [03:02<00:20,  2.97s/it]\u001b[A\n",
      " 88%|█████████████████████████████████████▊     | 44/50 [03:04<00:16,  2.80s/it]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 45/50 [03:07<00:13,  2.74s/it]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 46/50 [03:09<00:10,  2.54s/it]\u001b[A\n",
      " 94%|████████████████████████████████████████▍  | 47/50 [03:12<00:08,  2.68s/it]\u001b[A\n",
      " 96%|█████████████████████████████████████████▎ | 48/50 [03:16<00:06,  3.20s/it]\u001b[A\n",
      " 98%|██████████████████████████████████████████▏| 49/50 [03:20<00:03,  3.43s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 31.355430000000002, 'eval_rouge-2': 6.669668000000001, 'eval_rouge-l': 23.828198, 'eval_bleu-4': 0.03372050284194919, 'eval_runtime': 206.6822, 'eval_samples_per_second': 0.242, 'eval_steps_per_second': 0.242, 'epoch': 0.03}\n",
      "100%|███████████████████████████████████████| 3000/3000 [32:31<00:00,  4.91it/s]\n",
      "100%|███████████████████████████████████████████| 50/50 [03:23<00:00,  3.36s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-3000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/a5ba5501eb873d40d48bd0983bd2a8dd006bb838/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.39.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./output/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-3000/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 1952.6405, 'train_samples_per_second': 1.536, 'train_steps_per_second': 1.536, 'train_loss': 3.4300026041666665, 'epoch': 0.03}\n",
      "100%|███████████████████████████████████████| 3000/3000 [32:32<00:00,  1.54it/s]\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1070\n",
      "  Batch size = 1\n",
      "100%|█████████████████████████████████████| 1070/1070 [1:09:25<00:00,  3.89s/it]\n"
     ]
    }
   ],
   "source": [
    "!python finetune_hf.py  data/AdvertiseGen_fix  THUDM/chatglm3-6b  configs/lora.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9418f6c5c264601",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 3. 使用微调的数据集进行推理\n",
    "在完成微调任务之后，我们可以查看到 `output` 文件夹下多了很多个`checkpoint-*`的文件夹，这些文件夹代表了训练的轮数。\n",
    "我们选择最后一轮的微调权重，并使用inference进行导入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f22b735175e1c0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T07:03:19.390123Z",
     "start_time": "2024-01-18T07:03:19.246666Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint-1000  checkpoint-2000  checkpoint-3000\n",
      "checkpoint-1500  checkpoint-2500  checkpoint-500\n"
     ]
    }
   ],
   "source": [
    "!ls output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a24ddb93-6498-47e1-a2c7-7188a16f1077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "# 定义全局变量和参数\n",
    "model_name_or_path = 'THUDM/chatglm3-6b'  # 模型ID或本地路径\n",
    "peft_model_path = \"output/checkpoint-3000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af5339f5-6d10-4189-b291-7d7659bcafdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a901a5f44e454e9b43cbd03b126de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ChatGLMForConditionalGeneration(\n",
       "  (transformer): ChatGLMModel(\n",
       "    (embedding): Embedding(\n",
       "      (word_embeddings): Embedding(65024, 4096)\n",
       "    )\n",
       "    (rotary_pos_emb): RotaryEmbedding()\n",
       "    (encoder): GLMTransformer(\n",
       "      (layers): ModuleList(\n",
       "        (0-27): 28 x GLMBlock(\n",
       "          (input_layernorm): RMSNorm()\n",
       "          (self_attention): SelfAttention(\n",
       "            (query_key_value): Linear4bit(in_features=4096, out_features=4608, bias=True)\n",
       "            (core_attention): CoreAttention(\n",
       "              (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (dense): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (post_attention_layernorm): RMSNorm()\n",
       "          (mlp): MLP(\n",
       "            (dense_h_to_4h): Linear4bit(in_features=4096, out_features=27392, bias=False)\n",
       "            (dense_4h_to_h): Linear4bit(in_features=13696, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layernorm): RMSNorm()\n",
       "    )\n",
       "    (output_layer): Linear(in_features=4096, out_features=65024, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = PeftConfig.from_pretrained(peft_model_path)\n",
    "\n",
    "q_config = BitsAndBytesConfig(load_in_4bit=True,\n",
    "                              bnb_4bit_quant_type='nf4',\n",
    "                              bnb_4bit_use_double_quant=True,\n",
    "                              bnb_4bit_compute_dtype=torch.float32)\n",
    "\n",
    "base_model = AutoModel.from_pretrained(config.base_model_name_or_path,\n",
    "                                       quantization_config=q_config,\n",
    "                                       trust_remote_code=True,\n",
    "                                       device_map='auto')\n",
    "base_model.requires_grad_(False)\n",
    "base_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1435b23a-0745-4f67-86ad-4def56b845b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入：\n",
      "类型#裙*版型#显瘦*风格#文艺*风格#简约*图案#印花*图案#撞色*裙下摆#压褶*裙长#连衣裙*裙领型#圆领\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting eos_token is not supported, use the default one.\n",
      "Setting pad_token is not supported, use the default one.\n",
      "Setting unk_token is not supported, use the default one.\n"
     ]
    }
   ],
   "source": [
    "input_text = '类型#裙*版型#显瘦*风格#文艺*风格#简约*图案#印花*图案#撞色*裙下摆#压褶*裙长#连衣裙*裙领型#圆领'\n",
    "print(f'输入：\\n{input_text}')\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecb9c0b2-d39b-415b-9b77-80a2f7807763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.11/site-packages/bitsandbytes/nn/modules.py:226: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGLM3-6B 微调后: \n",
      "这款连衣裙的圆领设计，简约大气，凸显出女性的优雅气质。撞色的设计，打破常规，彰显出别样的时尚感。简约的圆领设计，修饰出女性的颈部线条，凸显出女性的优雅气质。简约的圆领设计，修饰出女性的颈部线条，凸显出女性的优雅气质。裙身压褶的设计，凸显出女性的柔美气质。\n"
     ]
    }
   ],
   "source": [
    "model = PeftModel.from_pretrained(base_model, peft_model_path)\n",
    "response, history = model.chat(tokenizer=tokenizer, query=input_text)\n",
    "print(f'ChatGLM3-6B 微调后: \\n{response}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5060015c24e97ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T07:08:13.616364Z",
     "start_time": "2024-01-18T07:07:07.346906Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# !python inference_hf.py output/checkpoint-2000/ --prompt \"类型#裙*版型#显瘦*材质#网纱*风格#性感*裙型#百褶*裙下摆#压褶*裙长#连衣裙*裙衣门襟#拉链*裙衣门襟#套头*裙款式#拼接*裙款式#拉链*裙款式#木耳边*裙款式#抽褶*裙款式#不规则\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cd83087f096094",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 4. 总结\n",
    "到此位置，我们就完成了使用单张 GPU Lora 来微调 ChatGLM3-6B 模型，使其能生产出更好的广告。\n",
    "在本章节中，你将会学会：\n",
    "+ 如何使用模型进行 Lora 微调\n",
    "+ 微调数据集的准备和对齐\n",
    "+ 使用微调的模型进行推理"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
